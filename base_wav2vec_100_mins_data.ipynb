{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available is cuda\n",
      "Sample Rate of model: 16000\n"
     ]
    }
   ],
   "source": [
    "##################################################################################################\n",
    "# First things first! Set a seed for reproducibility.\n",
    "# https://www.cs.mcgill.ca/~ksinha4/practices_for_reproducibility/\n",
    "def set_seed(seed):\n",
    "    \"\"\"Set seed\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "##################################################################################################\n",
    "writer = SummaryWriter()\n",
    "writer = SummaryWriter(\"wav2vec_base_model\")\n",
    "writer = SummaryWriter(comment=\"2D conv layer architecture from edge impulse ; lr = 0.0001; 100 epochs; 100 hours data\")\n",
    "##################################################################################################\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device available is', device)\n",
    "# wav2vec2.0\n",
    "bundle = torchaudio.pipelines.WAV2VEC2_BASE\n",
    "print(\"Sample Rate of model:\", bundle.sample_rate)\n",
    "\n",
    "model_wav2vec = bundle.get_model().to(device)\n",
    "## Convert audio to numpy to wav2vec feature encodings\n",
    "def conv_audio_data (filename) :\n",
    "    waveform, sample_rate = torchaudio.load(filename)\n",
    "    waveform = waveform.to(device)\n",
    "    if sample_rate != bundle.sample_rate:\n",
    "        print('Mismatched sample rate')\n",
    "        waveform = torchaudio.functional.resample(waveform, sample_rate, bundle.sample_rate)\n",
    "    emission, _ = model_wav2vec(waveform)\n",
    "    emission = emission.cpu().detach().numpy()\n",
    "    return emission\n",
    "\n",
    "x_f = []\n",
    "y_f = []\n",
    "x_s = []\n",
    "y_s = []\n",
    "# get all stutter data\n",
    "path_stutter  = \"Dataset/all_stutter/\"\n",
    "files_stutter = os.listdir(path_stutter)\n",
    "\n",
    "for filename in glob.glob(os.path.join(path_stutter, '*.wav')):\n",
    "    stutter_np = conv_audio_data(filename)\n",
    "    x_s.append(stutter_np)\n",
    "    y_s.append(1)\n",
    "\n",
    "# get all fluent data\n",
    "discarded = 0\n",
    "#FIXME :: How can I avoid discarding the mismatched samples?\n",
    "path_fluent  = \"Dataset/all_fluent/\"\n",
    "files_fluent = os.listdir(path_fluent)\n",
    "for filename in glob.glob(os.path.join(path_fluent, '*.wav')):\n",
    "    fluent_np = conv_audio_data(filename)\n",
    "    # fluent_np --> (1, 149, 768)\n",
    "    if ((np.shape(fluent_np)[0] != 1) |(np.shape(fluent_np)[1] != 149) | (np.shape(fluent_np)[2] != 768)) :\n",
    "        discarded += 1\n",
    "    else:\n",
    "        x_f.append(fluent_np)\n",
    "        y_f.append(0)\n",
    "\n",
    "# Shuffle all data within a class so that we have samples from all podcasts.\n",
    "random.shuffle(x_f)\n",
    "random.shuffle(x_s)\n",
    "\n",
    "# 100 samples each for 100  mins training\n",
    "x_f_train = x_f[0:2000]\n",
    "y_f_train = y_f[0:2000]\n",
    "x_s_train = x_s[0:2000]\n",
    "y_s_train = y_s[0:2000]\n",
    "\n",
    "\n",
    "# 100 samples each for 10 mins testing\n",
    "x_f_test = x_f[-100:-1]\n",
    "y_f_test = y_f[-100:-1]\n",
    "x_s_test = x_s[-100:-1]\n",
    "y_s_test = y_s[-100:-1]\n",
    "\n",
    "# FIXME :: Shuffle this later on so that all classesa re not given sequentially for training\n",
    "x_train = x_f_train + x_s_train\n",
    "y_train = y_f_train + y_s_train\n",
    "\n",
    "x_test = x_f_test + x_s_test\n",
    "y_test = y_f_test + y_s_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples to train =  4000\n",
      "Number of samples to test =  198\n"
     ]
    }
   ],
   "source": [
    "## Hyper parameters\n",
    "batch_size = 512\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# split data and translate to dataloader\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=123)\n",
    "\n",
    "n_samples_train = np.shape(x_train)[0]\n",
    "n_samples_test = np.shape(x_test)[0]\n",
    "print('Number of samples to train = ', n_samples_train)\n",
    "print('Number of samples to test = ', n_samples_test)\n",
    "\n",
    "class AudioDataset(Dataset) :\n",
    "    def __init__(self,x,y, n_samples) :\n",
    "        # data loading\n",
    "        self.x = x\n",
    "        self.y = y \n",
    "        self.n_samples = n_samples\n",
    "        \n",
    "        \n",
    "    def __getitem__(self,index) :\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self) :    \n",
    "        return self.n_samples      \n",
    "\n",
    "train_dataset = AudioDataset(x_train,y_train,n_samples_train)\n",
    "test_dataset = AudioDataset(x_test,y_test,n_samples_test)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=1)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StutterNet(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=113664, out_features=2, bias=True)\n",
      ")\n",
      "Epoch [1/100], Step [2/8], Loss: 11.1838, Acc : 46.484375%\n",
      "Epoch [1/100], Step [4/8], Loss: 6.7896, Acc : 53.3203125%\n",
      "Epoch [1/100], Step [6/8], Loss: 9.6439, Acc : 43.9453125%\n",
      "Epoch [1/100], Step [8/8], Loss: 1.7799, Acc : 51.92308044433594%\n",
      "Epoch [2/100], Step [2/8], Loss: 3.3891, Acc : 55.46875%\n",
      "Epoch [2/100], Step [4/8], Loss: 4.1418, Acc : 49.21875%\n",
      "Epoch [2/100], Step [6/8], Loss: 1.9353, Acc : 49.4140625%\n",
      "Epoch [2/100], Step [8/8], Loss: 0.9354, Acc : 52.64423370361328%\n",
      "Epoch [3/100], Step [2/8], Loss: 2.0221, Acc : 49.21875%\n",
      "Epoch [3/100], Step [4/8], Loss: 1.7383, Acc : 49.4140625%\n",
      "Epoch [3/100], Step [6/8], Loss: 0.9190, Acc : 50.9765625%\n",
      "Epoch [3/100], Step [8/8], Loss: 0.7180, Acc : 48.79808044433594%\n",
      "Epoch [4/100], Step [2/8], Loss: 0.8980, Acc : 54.4921875%\n",
      "Epoch [4/100], Step [4/8], Loss: 1.0511, Acc : 48.6328125%\n",
      "Epoch [4/100], Step [6/8], Loss: 0.8885, Acc : 50.1953125%\n",
      "Epoch [4/100], Step [8/8], Loss: 0.7207, Acc : 52.64423370361328%\n",
      "Epoch [5/100], Step [2/8], Loss: 0.6827, Acc : 58.984375%\n",
      "Epoch [5/100], Step [4/8], Loss: 0.7137, Acc : 48.2421875%\n",
      "Epoch [5/100], Step [6/8], Loss: 0.7410, Acc : 48.828125%\n",
      "Epoch [5/100], Step [8/8], Loss: 0.7665, Acc : 47.355770111083984%\n",
      "Epoch [6/100], Step [2/8], Loss: 0.7170, Acc : 51.953125%\n",
      "Epoch [6/100], Step [4/8], Loss: 0.7238, Acc : 48.4375%\n",
      "Epoch [6/100], Step [6/8], Loss: 0.6835, Acc : 52.9296875%\n",
      "Epoch [6/100], Step [8/8], Loss: 0.6905, Acc : 53.125003814697266%\n",
      "Epoch [7/100], Step [2/8], Loss: 0.6817, Acc : 61.328125%\n",
      "Epoch [7/100], Step [4/8], Loss: 0.6785, Acc : 55.6640625%\n",
      "Epoch [7/100], Step [6/8], Loss: 0.6953, Acc : 45.8984375%\n",
      "Epoch [7/100], Step [8/8], Loss: 0.6919, Acc : 50.0%\n",
      "Epoch [8/100], Step [2/8], Loss: 0.6794, Acc : 53.90625%\n",
      "Epoch [8/100], Step [4/8], Loss: 0.6920, Acc : 48.6328125%\n",
      "Epoch [8/100], Step [6/8], Loss: 0.6885, Acc : 50.0%\n",
      "Epoch [8/100], Step [8/8], Loss: 0.6833, Acc : 56.730770111083984%\n",
      "Epoch [9/100], Step [2/8], Loss: 0.6822, Acc : 55.859375%\n",
      "Epoch [9/100], Step [4/8], Loss: 0.6832, Acc : 57.421875%\n",
      "Epoch [9/100], Step [6/8], Loss: 0.6836, Acc : 57.6171875%\n",
      "Epoch [9/100], Step [8/8], Loss: 0.6816, Acc : 57.69231033325195%\n",
      "Epoch [10/100], Step [2/8], Loss: 0.6796, Acc : 58.203125%\n",
      "Epoch [10/100], Step [4/8], Loss: 0.6821, Acc : 55.2734375%\n",
      "Epoch [10/100], Step [6/8], Loss: 0.6832, Acc : 55.46875%\n",
      "Epoch [10/100], Step [8/8], Loss: 0.6780, Acc : 58.653846740722656%\n",
      "Epoch [11/100], Step [2/8], Loss: 0.6749, Acc : 61.9140625%\n",
      "Epoch [11/100], Step [4/8], Loss: 0.6792, Acc : 57.8125%\n",
      "Epoch [11/100], Step [6/8], Loss: 0.6823, Acc : 57.2265625%\n",
      "Epoch [11/100], Step [8/8], Loss: 0.6817, Acc : 60.576927185058594%\n",
      "Epoch [12/100], Step [2/8], Loss: 0.6813, Acc : 56.25%\n",
      "Epoch [12/100], Step [4/8], Loss: 0.6777, Acc : 59.9609375%\n",
      "Epoch [12/100], Step [6/8], Loss: 0.6784, Acc : 60.15625%\n",
      "Epoch [12/100], Step [8/8], Loss: 0.6853, Acc : 56.00961685180664%\n",
      "Epoch [13/100], Step [2/8], Loss: 0.6764, Acc : 60.546875%\n",
      "Epoch [13/100], Step [4/8], Loss: 0.6749, Acc : 61.9140625%\n",
      "Epoch [13/100], Step [6/8], Loss: 0.6775, Acc : 59.5703125%\n",
      "Epoch [13/100], Step [8/8], Loss: 0.6752, Acc : 59.615386962890625%\n",
      "Epoch [14/100], Step [2/8], Loss: 0.6750, Acc : 62.109375%\n",
      "Epoch [14/100], Step [4/8], Loss: 0.6768, Acc : 58.0078125%\n",
      "Epoch [14/100], Step [6/8], Loss: 0.6736, Acc : 60.9375%\n",
      "Epoch [14/100], Step [8/8], Loss: 0.6722, Acc : 62.25961685180664%\n",
      "Epoch [15/100], Step [2/8], Loss: 0.6749, Acc : 60.546875%\n",
      "Epoch [15/100], Step [4/8], Loss: 0.6718, Acc : 61.9140625%\n",
      "Epoch [15/100], Step [6/8], Loss: 0.6725, Acc : 58.984375%\n",
      "Epoch [15/100], Step [8/8], Loss: 0.6714, Acc : 62.500003814697266%\n",
      "Epoch [16/100], Step [2/8], Loss: 0.6692, Acc : 62.890625%\n",
      "Epoch [16/100], Step [4/8], Loss: 0.6739, Acc : 57.8125%\n",
      "Epoch [16/100], Step [6/8], Loss: 0.6775, Acc : 56.640625%\n",
      "Epoch [16/100], Step [8/8], Loss: 0.6711, Acc : 60.81731033325195%\n",
      "Epoch [17/100], Step [2/8], Loss: 0.6699, Acc : 61.9140625%\n",
      "Epoch [17/100], Step [4/8], Loss: 0.6759, Acc : 58.3984375%\n",
      "Epoch [17/100], Step [6/8], Loss: 0.6680, Acc : 61.9140625%\n",
      "Epoch [17/100], Step [8/8], Loss: 0.6724, Acc : 59.615386962890625%\n",
      "Epoch [18/100], Step [2/8], Loss: 0.6708, Acc : 60.546875%\n",
      "Epoch [18/100], Step [4/8], Loss: 0.6709, Acc : 58.203125%\n",
      "Epoch [18/100], Step [6/8], Loss: 0.6725, Acc : 57.2265625%\n",
      "Epoch [18/100], Step [8/8], Loss: 0.6753, Acc : 57.93269348144531%\n",
      "Epoch [19/100], Step [2/8], Loss: 0.6638, Acc : 61.1328125%\n",
      "Epoch [19/100], Step [4/8], Loss: 0.6750, Acc : 56.8359375%\n",
      "Epoch [19/100], Step [6/8], Loss: 0.6679, Acc : 62.109375%\n",
      "Epoch [19/100], Step [8/8], Loss: 0.6569, Acc : 66.34615325927734%\n",
      "Epoch [20/100], Step [2/8], Loss: 0.6680, Acc : 60.546875%\n",
      "Epoch [20/100], Step [4/8], Loss: 0.6653, Acc : 59.765625%\n",
      "Epoch [20/100], Step [6/8], Loss: 0.6633, Acc : 61.5234375%\n",
      "Epoch [20/100], Step [8/8], Loss: 0.6667, Acc : 59.615386962890625%\n",
      "Epoch [21/100], Step [2/8], Loss: 0.6655, Acc : 60.546875%\n",
      "Epoch [21/100], Step [4/8], Loss: 0.6659, Acc : 59.9609375%\n",
      "Epoch [21/100], Step [6/8], Loss: 0.6545, Acc : 61.5234375%\n",
      "Epoch [21/100], Step [8/8], Loss: 0.6613, Acc : 62.980770111083984%\n",
      "Epoch [22/100], Step [2/8], Loss: 0.6709, Acc : 58.203125%\n",
      "Epoch [22/100], Step [4/8], Loss: 0.6647, Acc : 58.7890625%\n",
      "Epoch [22/100], Step [6/8], Loss: 0.6552, Acc : 62.6953125%\n",
      "Epoch [22/100], Step [8/8], Loss: 0.6629, Acc : 59.855770111083984%\n",
      "Epoch [23/100], Step [2/8], Loss: 0.6614, Acc : 62.109375%\n",
      "Epoch [23/100], Step [4/8], Loss: 0.6565, Acc : 63.0859375%\n",
      "Epoch [23/100], Step [6/8], Loss: 0.6609, Acc : 60.7421875%\n",
      "Epoch [23/100], Step [8/8], Loss: 0.6647, Acc : 61.778846740722656%\n",
      "Epoch [24/100], Step [2/8], Loss: 0.6616, Acc : 58.7890625%\n",
      "Epoch [24/100], Step [4/8], Loss: 0.6652, Acc : 58.3984375%\n",
      "Epoch [24/100], Step [6/8], Loss: 0.6581, Acc : 61.5234375%\n",
      "Epoch [24/100], Step [8/8], Loss: 0.6474, Acc : 62.740386962890625%\n",
      "Epoch [25/100], Step [2/8], Loss: 0.6597, Acc : 61.1328125%\n",
      "Epoch [25/100], Step [4/8], Loss: 0.6591, Acc : 58.7890625%\n",
      "Epoch [25/100], Step [6/8], Loss: 0.6565, Acc : 62.109375%\n",
      "Epoch [25/100], Step [8/8], Loss: 0.6562, Acc : 61.05769348144531%\n",
      "Epoch [26/100], Step [2/8], Loss: 0.6456, Acc : 63.4765625%\n",
      "Epoch [26/100], Step [4/8], Loss: 0.6619, Acc : 59.765625%\n",
      "Epoch [26/100], Step [6/8], Loss: 0.6473, Acc : 61.1328125%\n",
      "Epoch [26/100], Step [8/8], Loss: 0.6431, Acc : 66.34615325927734%\n",
      "Epoch [27/100], Step [2/8], Loss: 0.6393, Acc : 64.2578125%\n",
      "Epoch [27/100], Step [4/8], Loss: 0.6563, Acc : 60.546875%\n",
      "Epoch [27/100], Step [6/8], Loss: 0.6426, Acc : 64.0625%\n",
      "Epoch [27/100], Step [8/8], Loss: 0.6609, Acc : 61.29808044433594%\n",
      "Epoch [28/100], Step [2/8], Loss: 0.6395, Acc : 63.0859375%\n",
      "Epoch [28/100], Step [4/8], Loss: 0.6472, Acc : 61.71875%\n",
      "Epoch [28/100], Step [6/8], Loss: 0.6475, Acc : 62.6953125%\n",
      "Epoch [28/100], Step [8/8], Loss: 0.6342, Acc : 64.66346740722656%\n",
      "Epoch [29/100], Step [2/8], Loss: 0.6476, Acc : 62.890625%\n",
      "Epoch [29/100], Step [4/8], Loss: 0.6433, Acc : 62.5%\n",
      "Epoch [29/100], Step [6/8], Loss: 0.6526, Acc : 59.765625%\n",
      "Epoch [29/100], Step [8/8], Loss: 0.6246, Acc : 65.625%\n",
      "Epoch [30/100], Step [2/8], Loss: 0.6519, Acc : 59.375%\n",
      "Epoch [30/100], Step [4/8], Loss: 0.6523, Acc : 62.109375%\n",
      "Epoch [30/100], Step [6/8], Loss: 0.6479, Acc : 62.5%\n",
      "Epoch [30/100], Step [8/8], Loss: 0.6410, Acc : 61.778846740722656%\n",
      "Epoch [31/100], Step [2/8], Loss: 0.6428, Acc : 62.109375%\n",
      "Epoch [31/100], Step [4/8], Loss: 0.6615, Acc : 59.1796875%\n",
      "Epoch [31/100], Step [6/8], Loss: 0.6171, Acc : 64.84375%\n",
      "Epoch [31/100], Step [8/8], Loss: 0.6561, Acc : 59.615386962890625%\n",
      "Epoch [32/100], Step [2/8], Loss: 0.6226, Acc : 65.234375%\n",
      "Epoch [32/100], Step [4/8], Loss: 0.6626, Acc : 58.59375%\n",
      "Epoch [32/100], Step [6/8], Loss: 0.6349, Acc : 63.28125%\n",
      "Epoch [32/100], Step [8/8], Loss: 0.6189, Acc : 66.10577392578125%\n",
      "Epoch [33/100], Step [2/8], Loss: 0.6365, Acc : 61.9140625%\n",
      "Epoch [33/100], Step [4/8], Loss: 0.6304, Acc : 64.453125%\n",
      "Epoch [33/100], Step [6/8], Loss: 0.6492, Acc : 61.5234375%\n",
      "Epoch [33/100], Step [8/8], Loss: 0.6259, Acc : 65.86538696289062%\n",
      "Epoch [34/100], Step [2/8], Loss: 0.6454, Acc : 60.15625%\n",
      "Epoch [34/100], Step [4/8], Loss: 0.6189, Acc : 66.40625%\n",
      "Epoch [34/100], Step [6/8], Loss: 0.6166, Acc : 66.6015625%\n",
      "Epoch [34/100], Step [8/8], Loss: 0.6365, Acc : 64.66346740722656%\n",
      "Epoch [35/100], Step [2/8], Loss: 0.6102, Acc : 67.3828125%\n",
      "Epoch [35/100], Step [4/8], Loss: 0.6262, Acc : 62.890625%\n",
      "Epoch [35/100], Step [6/8], Loss: 0.5976, Acc : 66.2109375%\n",
      "Epoch [35/100], Step [8/8], Loss: 0.6303, Acc : 63.701927185058594%\n",
      "Epoch [36/100], Step [2/8], Loss: 0.6075, Acc : 65.234375%\n",
      "Epoch [36/100], Step [4/8], Loss: 0.6325, Acc : 63.4765625%\n",
      "Epoch [36/100], Step [6/8], Loss: 0.5983, Acc : 66.9921875%\n",
      "Epoch [36/100], Step [8/8], Loss: 0.6151, Acc : 65.86538696289062%\n",
      "Epoch [37/100], Step [2/8], Loss: 0.6078, Acc : 65.234375%\n",
      "Epoch [37/100], Step [4/8], Loss: 0.6040, Acc : 66.40625%\n",
      "Epoch [37/100], Step [6/8], Loss: 0.6159, Acc : 65.625%\n",
      "Epoch [37/100], Step [8/8], Loss: 0.5877, Acc : 68.26923370361328%\n",
      "Epoch [38/100], Step [2/8], Loss: 0.6074, Acc : 66.6015625%\n",
      "Epoch [38/100], Step [4/8], Loss: 0.5950, Acc : 69.7265625%\n",
      "Epoch [38/100], Step [6/8], Loss: 0.5905, Acc : 68.359375%\n",
      "Epoch [38/100], Step [8/8], Loss: 0.5980, Acc : 68.26923370361328%\n",
      "Epoch [39/100], Step [2/8], Loss: 0.5778, Acc : 72.0703125%\n",
      "Epoch [39/100], Step [4/8], Loss: 0.6029, Acc : 69.53125%\n",
      "Epoch [39/100], Step [6/8], Loss: 0.5832, Acc : 67.7734375%\n",
      "Epoch [39/100], Step [8/8], Loss: 0.5751, Acc : 69.9519271850586%\n",
      "Epoch [40/100], Step [2/8], Loss: 0.5994, Acc : 66.796875%\n",
      "Epoch [40/100], Step [4/8], Loss: 0.5975, Acc : 68.75%\n",
      "Epoch [40/100], Step [6/8], Loss: 0.5573, Acc : 72.0703125%\n",
      "Epoch [40/100], Step [8/8], Loss: 0.5730, Acc : 69.9519271850586%\n",
      "Epoch [41/100], Step [2/8], Loss: 0.5685, Acc : 68.359375%\n",
      "Epoch [41/100], Step [4/8], Loss: 0.5905, Acc : 68.359375%\n",
      "Epoch [41/100], Step [6/8], Loss: 0.5656, Acc : 68.5546875%\n",
      "Epoch [41/100], Step [8/8], Loss: 0.5629, Acc : 71.875%\n",
      "Epoch [42/100], Step [2/8], Loss: 0.5619, Acc : 72.0703125%\n",
      "Epoch [42/100], Step [4/8], Loss: 0.5441, Acc : 73.046875%\n",
      "Epoch [42/100], Step [6/8], Loss: 0.5334, Acc : 74.0234375%\n",
      "Epoch [42/100], Step [8/8], Loss: 0.5840, Acc : 69.71154022216797%\n",
      "Epoch [43/100], Step [2/8], Loss: 0.5194, Acc : 75.1953125%\n",
      "Epoch [43/100], Step [4/8], Loss: 0.5372, Acc : 74.0234375%\n",
      "Epoch [43/100], Step [6/8], Loss: 0.5619, Acc : 70.1171875%\n",
      "Epoch [43/100], Step [8/8], Loss: 0.5575, Acc : 69.47115325927734%\n",
      "Epoch [44/100], Step [2/8], Loss: 0.5517, Acc : 69.7265625%\n",
      "Epoch [44/100], Step [4/8], Loss: 0.5147, Acc : 75.0%\n",
      "Epoch [44/100], Step [6/8], Loss: 0.5155, Acc : 75.1953125%\n",
      "Epoch [44/100], Step [8/8], Loss: 0.5597, Acc : 70.67308044433594%\n",
      "Epoch [45/100], Step [2/8], Loss: 0.5554, Acc : 70.1171875%\n",
      "Epoch [45/100], Step [4/8], Loss: 0.5337, Acc : 73.6328125%\n",
      "Epoch [45/100], Step [6/8], Loss: 0.5401, Acc : 70.703125%\n",
      "Epoch [45/100], Step [8/8], Loss: 0.5684, Acc : 71.15384674072266%\n",
      "Epoch [46/100], Step [2/8], Loss: 0.5211, Acc : 74.4140625%\n",
      "Epoch [46/100], Step [4/8], Loss: 0.5719, Acc : 72.4609375%\n",
      "Epoch [46/100], Step [6/8], Loss: 0.5612, Acc : 69.7265625%\n",
      "Epoch [46/100], Step [8/8], Loss: 0.5813, Acc : 70.67308044433594%\n",
      "Epoch [47/100], Step [2/8], Loss: 0.5061, Acc : 76.7578125%\n",
      "Epoch [47/100], Step [4/8], Loss: 0.5049, Acc : 77.5390625%\n",
      "Epoch [47/100], Step [6/8], Loss: 0.5476, Acc : 70.3125%\n",
      "Epoch [47/100], Step [8/8], Loss: 0.6372, Acc : 63.94231033325195%\n",
      "Epoch [48/100], Step [2/8], Loss: 0.5406, Acc : 71.2890625%\n",
      "Epoch [48/100], Step [4/8], Loss: 0.5237, Acc : 73.4375%\n",
      "Epoch [48/100], Step [6/8], Loss: 0.5315, Acc : 72.265625%\n",
      "Epoch [48/100], Step [8/8], Loss: 0.5726, Acc : 71.39423370361328%\n",
      "Epoch [49/100], Step [2/8], Loss: 0.5275, Acc : 73.046875%\n",
      "Epoch [49/100], Step [4/8], Loss: 0.5073, Acc : 76.5625%\n",
      "Epoch [49/100], Step [6/8], Loss: 0.5309, Acc : 73.046875%\n",
      "Epoch [49/100], Step [8/8], Loss: 0.5282, Acc : 70.67308044433594%\n",
      "Epoch [50/100], Step [2/8], Loss: 0.5067, Acc : 74.4140625%\n",
      "Epoch [50/100], Step [4/8], Loss: 0.4781, Acc : 77.1484375%\n",
      "Epoch [50/100], Step [6/8], Loss: 0.4881, Acc : 77.1484375%\n",
      "Epoch [50/100], Step [8/8], Loss: 0.5345, Acc : 74.03846740722656%\n",
      "Epoch [51/100], Step [2/8], Loss: 0.5189, Acc : 74.609375%\n",
      "Epoch [51/100], Step [4/8], Loss: 0.5048, Acc : 72.8515625%\n",
      "Epoch [51/100], Step [6/8], Loss: 0.4972, Acc : 75.78125%\n",
      "Epoch [51/100], Step [8/8], Loss: 0.5356, Acc : 73.0769271850586%\n",
      "Epoch [52/100], Step [2/8], Loss: 0.5040, Acc : 73.6328125%\n",
      "Epoch [52/100], Step [4/8], Loss: 0.4908, Acc : 77.1484375%\n",
      "Epoch [52/100], Step [6/8], Loss: 0.4476, Acc : 79.6875%\n",
      "Epoch [52/100], Step [8/8], Loss: 0.5095, Acc : 75.48077392578125%\n",
      "Epoch [53/100], Step [2/8], Loss: 0.4697, Acc : 76.953125%\n",
      "Epoch [53/100], Step [4/8], Loss: 0.5029, Acc : 74.21875%\n",
      "Epoch [53/100], Step [6/8], Loss: 0.4937, Acc : 75.0%\n",
      "Epoch [53/100], Step [8/8], Loss: 0.5121, Acc : 73.55769348144531%\n",
      "Epoch [54/100], Step [2/8], Loss: 0.4673, Acc : 77.9296875%\n",
      "Epoch [54/100], Step [4/8], Loss: 0.4749, Acc : 76.5625%\n",
      "Epoch [54/100], Step [6/8], Loss: 0.5432, Acc : 73.2421875%\n",
      "Epoch [54/100], Step [8/8], Loss: 0.5097, Acc : 74.03846740722656%\n",
      "Epoch [55/100], Step [2/8], Loss: 0.4856, Acc : 74.609375%\n",
      "Epoch [55/100], Step [4/8], Loss: 0.4826, Acc : 77.734375%\n",
      "Epoch [55/100], Step [6/8], Loss: 0.5370, Acc : 73.6328125%\n",
      "Epoch [55/100], Step [8/8], Loss: 0.4434, Acc : 77.64423370361328%\n",
      "Epoch [56/100], Step [2/8], Loss: 0.4930, Acc : 75.1953125%\n",
      "Epoch [56/100], Step [4/8], Loss: 0.4322, Acc : 80.078125%\n",
      "Epoch [56/100], Step [6/8], Loss: 0.5022, Acc : 74.4140625%\n",
      "Epoch [56/100], Step [8/8], Loss: 0.4990, Acc : 73.55769348144531%\n",
      "Epoch [57/100], Step [2/8], Loss: 0.4738, Acc : 77.1484375%\n",
      "Epoch [57/100], Step [4/8], Loss: 0.4537, Acc : 78.90625%\n",
      "Epoch [57/100], Step [6/8], Loss: 0.4754, Acc : 76.171875%\n",
      "Epoch [57/100], Step [8/8], Loss: 0.4704, Acc : 78.125%\n",
      "Epoch [58/100], Step [2/8], Loss: 0.4800, Acc : 75.5859375%\n",
      "Epoch [58/100], Step [4/8], Loss: 0.4548, Acc : 78.7109375%\n",
      "Epoch [58/100], Step [6/8], Loss: 0.4863, Acc : 77.1484375%\n",
      "Epoch [58/100], Step [8/8], Loss: 0.4526, Acc : 75.0%\n",
      "Epoch [59/100], Step [2/8], Loss: 0.4610, Acc : 79.296875%\n",
      "Epoch [59/100], Step [4/8], Loss: 0.4715, Acc : 77.34375%\n",
      "Epoch [59/100], Step [6/8], Loss: 0.4757, Acc : 74.609375%\n",
      "Epoch [59/100], Step [8/8], Loss: 0.4490, Acc : 78.60577392578125%\n",
      "Epoch [60/100], Step [2/8], Loss: 0.4375, Acc : 81.4453125%\n",
      "Epoch [60/100], Step [4/8], Loss: 0.4759, Acc : 77.9296875%\n",
      "Epoch [60/100], Step [6/8], Loss: 0.4961, Acc : 76.5625%\n",
      "Epoch [60/100], Step [8/8], Loss: 0.5379, Acc : 74.7596206665039%\n",
      "Epoch [61/100], Step [2/8], Loss: 0.4998, Acc : 76.171875%\n",
      "Epoch [61/100], Step [4/8], Loss: 0.4934, Acc : 75.9765625%\n",
      "Epoch [61/100], Step [6/8], Loss: 0.5085, Acc : 74.21875%\n",
      "Epoch [61/100], Step [8/8], Loss: 0.4623, Acc : 76.2019271850586%\n",
      "Epoch [62/100], Step [2/8], Loss: 0.4443, Acc : 80.2734375%\n",
      "Epoch [62/100], Step [4/8], Loss: 0.4373, Acc : 78.90625%\n",
      "Epoch [62/100], Step [6/8], Loss: 0.4762, Acc : 75.1953125%\n",
      "Epoch [62/100], Step [8/8], Loss: 0.4745, Acc : 76.68269348144531%\n",
      "Epoch [63/100], Step [2/8], Loss: 0.4531, Acc : 76.3671875%\n",
      "Epoch [63/100], Step [4/8], Loss: 0.4160, Acc : 79.8828125%\n",
      "Epoch [63/100], Step [6/8], Loss: 0.4248, Acc : 79.4921875%\n",
      "Epoch [63/100], Step [8/8], Loss: 0.4027, Acc : 79.3269271850586%\n",
      "Epoch [64/100], Step [2/8], Loss: 0.4062, Acc : 83.0078125%\n",
      "Epoch [64/100], Step [4/8], Loss: 0.4152, Acc : 80.6640625%\n",
      "Epoch [64/100], Step [6/8], Loss: 0.4268, Acc : 78.90625%\n",
      "Epoch [64/100], Step [8/8], Loss: 0.4094, Acc : 81.97115325927734%\n",
      "Epoch [65/100], Step [2/8], Loss: 0.3876, Acc : 83.7890625%\n",
      "Epoch [65/100], Step [4/8], Loss: 0.4173, Acc : 81.640625%\n",
      "Epoch [65/100], Step [6/8], Loss: 0.4349, Acc : 76.953125%\n",
      "Epoch [65/100], Step [8/8], Loss: 0.4411, Acc : 80.04808044433594%\n",
      "Epoch [66/100], Step [2/8], Loss: 0.4594, Acc : 77.34375%\n",
      "Epoch [66/100], Step [4/8], Loss: 0.4849, Acc : 76.953125%\n",
      "Epoch [66/100], Step [6/8], Loss: 0.4660, Acc : 78.515625%\n",
      "Epoch [66/100], Step [8/8], Loss: 0.4482, Acc : 78.60577392578125%\n",
      "Epoch [67/100], Step [2/8], Loss: 0.4313, Acc : 81.0546875%\n",
      "Epoch [67/100], Step [4/8], Loss: 0.4157, Acc : 80.078125%\n",
      "Epoch [67/100], Step [6/8], Loss: 0.4431, Acc : 77.5390625%\n",
      "Epoch [67/100], Step [8/8], Loss: 0.4074, Acc : 80.28846740722656%\n",
      "Epoch [68/100], Step [2/8], Loss: 0.4222, Acc : 79.4921875%\n",
      "Epoch [68/100], Step [4/8], Loss: 0.4446, Acc : 78.3203125%\n",
      "Epoch [68/100], Step [6/8], Loss: 0.4342, Acc : 81.25%\n",
      "Epoch [68/100], Step [8/8], Loss: 0.4364, Acc : 80.52884674072266%\n",
      "Epoch [69/100], Step [2/8], Loss: 0.4188, Acc : 82.2265625%\n",
      "Epoch [69/100], Step [4/8], Loss: 0.4510, Acc : 77.1484375%\n",
      "Epoch [69/100], Step [6/8], Loss: 0.3998, Acc : 80.859375%\n",
      "Epoch [69/100], Step [8/8], Loss: 0.3889, Acc : 81.25%\n",
      "Epoch [70/100], Step [2/8], Loss: 0.4045, Acc : 81.640625%\n",
      "Epoch [70/100], Step [4/8], Loss: 0.4234, Acc : 78.515625%\n",
      "Epoch [70/100], Step [6/8], Loss: 0.4307, Acc : 79.6875%\n",
      "Epoch [70/100], Step [8/8], Loss: 0.3930, Acc : 82.69231414794922%\n",
      "Epoch [71/100], Step [2/8], Loss: 0.4210, Acc : 80.2734375%\n",
      "Epoch [71/100], Step [4/8], Loss: 0.4337, Acc : 80.6640625%\n",
      "Epoch [71/100], Step [6/8], Loss: 0.3839, Acc : 83.3984375%\n",
      "Epoch [71/100], Step [8/8], Loss: 0.3791, Acc : 81.97115325927734%\n",
      "Epoch [72/100], Step [2/8], Loss: 0.4144, Acc : 82.2265625%\n",
      "Epoch [72/100], Step [4/8], Loss: 0.3729, Acc : 81.4453125%\n",
      "Epoch [72/100], Step [6/8], Loss: 0.4344, Acc : 79.6875%\n",
      "Epoch [72/100], Step [8/8], Loss: 0.5024, Acc : 75.0%\n",
      "Epoch [73/100], Step [2/8], Loss: 0.5509, Acc : 71.875%\n",
      "Epoch [73/100], Step [4/8], Loss: 0.5157, Acc : 72.4609375%\n",
      "Epoch [73/100], Step [6/8], Loss: 0.4890, Acc : 73.828125%\n",
      "Epoch [73/100], Step [8/8], Loss: 0.4584, Acc : 77.8846206665039%\n",
      "Epoch [74/100], Step [2/8], Loss: 0.4246, Acc : 83.7890625%\n",
      "Epoch [74/100], Step [4/8], Loss: 0.4476, Acc : 77.734375%\n",
      "Epoch [74/100], Step [6/8], Loss: 0.4119, Acc : 80.078125%\n",
      "Epoch [74/100], Step [8/8], Loss: 0.4100, Acc : 80.04808044433594%\n",
      "Epoch [75/100], Step [2/8], Loss: 0.4531, Acc : 77.5390625%\n",
      "Epoch [75/100], Step [4/8], Loss: 0.4562, Acc : 77.1484375%\n",
      "Epoch [75/100], Step [6/8], Loss: 0.4897, Acc : 75.0%\n",
      "Epoch [75/100], Step [8/8], Loss: 0.4450, Acc : 76.68269348144531%\n",
      "Epoch [76/100], Step [2/8], Loss: 0.3992, Acc : 82.421875%\n",
      "Epoch [76/100], Step [4/8], Loss: 0.3743, Acc : 83.984375%\n",
      "Epoch [76/100], Step [6/8], Loss: 0.4378, Acc : 77.5390625%\n",
      "Epoch [76/100], Step [8/8], Loss: 0.3842, Acc : 82.93269348144531%\n",
      "Epoch [77/100], Step [2/8], Loss: 0.3841, Acc : 84.5703125%\n",
      "Epoch [77/100], Step [4/8], Loss: 0.3750, Acc : 83.984375%\n",
      "Epoch [77/100], Step [6/8], Loss: 0.4379, Acc : 78.90625%\n",
      "Epoch [77/100], Step [8/8], Loss: 0.3974, Acc : 82.21154022216797%\n",
      "Epoch [78/100], Step [2/8], Loss: 0.3607, Acc : 82.8125%\n",
      "Epoch [78/100], Step [4/8], Loss: 0.3771, Acc : 83.984375%\n",
      "Epoch [78/100], Step [6/8], Loss: 0.3673, Acc : 84.1796875%\n",
      "Epoch [78/100], Step [8/8], Loss: 0.3585, Acc : 83.89423370361328%\n",
      "Epoch [79/100], Step [2/8], Loss: 0.3983, Acc : 81.8359375%\n",
      "Epoch [79/100], Step [4/8], Loss: 0.4091, Acc : 81.4453125%\n",
      "Epoch [79/100], Step [6/8], Loss: 0.3764, Acc : 83.3984375%\n",
      "Epoch [79/100], Step [8/8], Loss: 0.3547, Acc : 86.77884674072266%\n",
      "Epoch [80/100], Step [2/8], Loss: 0.3726, Acc : 82.8125%\n",
      "Epoch [80/100], Step [4/8], Loss: 0.3826, Acc : 83.3984375%\n",
      "Epoch [80/100], Step [6/8], Loss: 0.3669, Acc : 81.4453125%\n",
      "Epoch [80/100], Step [8/8], Loss: 0.3998, Acc : 82.4519271850586%\n",
      "Epoch [81/100], Step [2/8], Loss: 0.3677, Acc : 83.7890625%\n",
      "Epoch [81/100], Step [4/8], Loss: 0.3881, Acc : 81.640625%\n",
      "Epoch [81/100], Step [6/8], Loss: 0.3616, Acc : 83.59375%\n",
      "Epoch [81/100], Step [8/8], Loss: 0.3881, Acc : 82.69231414794922%\n",
      "Epoch [82/100], Step [2/8], Loss: 0.3434, Acc : 84.1796875%\n",
      "Epoch [82/100], Step [4/8], Loss: 0.3923, Acc : 83.0078125%\n",
      "Epoch [82/100], Step [6/8], Loss: 0.3719, Acc : 85.15625%\n",
      "Epoch [82/100], Step [8/8], Loss: 0.3682, Acc : 82.93269348144531%\n",
      "Epoch [83/100], Step [2/8], Loss: 0.3662, Acc : 84.375%\n",
      "Epoch [83/100], Step [4/8], Loss: 0.3358, Acc : 86.9140625%\n",
      "Epoch [83/100], Step [6/8], Loss: 0.3822, Acc : 81.4453125%\n",
      "Epoch [83/100], Step [8/8], Loss: 0.3720, Acc : 84.375%\n",
      "Epoch [84/100], Step [2/8], Loss: 0.3590, Acc : 83.984375%\n",
      "Epoch [84/100], Step [4/8], Loss: 0.4071, Acc : 81.25%\n",
      "Epoch [84/100], Step [6/8], Loss: 0.3255, Acc : 84.9609375%\n",
      "Epoch [84/100], Step [8/8], Loss: 0.3833, Acc : 83.17308044433594%\n",
      "Epoch [85/100], Step [2/8], Loss: 0.3019, Acc : 86.328125%\n",
      "Epoch [85/100], Step [4/8], Loss: 0.3222, Acc : 85.7421875%\n",
      "Epoch [85/100], Step [6/8], Loss: 0.3304, Acc : 85.3515625%\n",
      "Epoch [85/100], Step [8/8], Loss: 0.3551, Acc : 84.375%\n",
      "Epoch [86/100], Step [2/8], Loss: 0.3312, Acc : 84.765625%\n",
      "Epoch [86/100], Step [4/8], Loss: 0.3685, Acc : 83.203125%\n",
      "Epoch [86/100], Step [6/8], Loss: 0.3346, Acc : 84.9609375%\n",
      "Epoch [86/100], Step [8/8], Loss: 0.3478, Acc : 83.89423370361328%\n",
      "Epoch [87/100], Step [2/8], Loss: 0.3748, Acc : 80.46875%\n",
      "Epoch [87/100], Step [4/8], Loss: 0.3715, Acc : 82.6171875%\n",
      "Epoch [87/100], Step [6/8], Loss: 0.4697, Acc : 77.1484375%\n",
      "Epoch [87/100], Step [8/8], Loss: 0.4516, Acc : 76.44231414794922%\n",
      "Epoch [88/100], Step [2/8], Loss: 0.3592, Acc : 82.2265625%\n",
      "Epoch [88/100], Step [4/8], Loss: 0.3704, Acc : 82.2265625%\n",
      "Epoch [88/100], Step [6/8], Loss: 0.3323, Acc : 85.15625%\n",
      "Epoch [88/100], Step [8/8], Loss: 0.3757, Acc : 84.61538696289062%\n",
      "Epoch [89/100], Step [2/8], Loss: 0.3739, Acc : 83.0078125%\n",
      "Epoch [89/100], Step [4/8], Loss: 0.3671, Acc : 83.984375%\n",
      "Epoch [89/100], Step [6/8], Loss: 0.3245, Acc : 88.28125%\n",
      "Epoch [89/100], Step [8/8], Loss: 0.3275, Acc : 84.1346206665039%\n",
      "Epoch [90/100], Step [2/8], Loss: 0.3657, Acc : 82.421875%\n",
      "Epoch [90/100], Step [4/8], Loss: 0.3151, Acc : 85.9375%\n",
      "Epoch [90/100], Step [6/8], Loss: 0.3712, Acc : 83.0078125%\n",
      "Epoch [90/100], Step [8/8], Loss: 0.3373, Acc : 84.1346206665039%\n",
      "Epoch [91/100], Step [2/8], Loss: 0.3548, Acc : 82.6171875%\n",
      "Epoch [91/100], Step [4/8], Loss: 0.3358, Acc : 83.984375%\n",
      "Epoch [91/100], Step [6/8], Loss: 0.3297, Acc : 85.9375%\n",
      "Epoch [91/100], Step [8/8], Loss: 0.3695, Acc : 83.65384674072266%\n",
      "Epoch [92/100], Step [2/8], Loss: 0.3087, Acc : 85.7421875%\n",
      "Epoch [92/100], Step [4/8], Loss: 0.3755, Acc : 83.59375%\n",
      "Epoch [92/100], Step [6/8], Loss: 0.3195, Acc : 86.9140625%\n",
      "Epoch [92/100], Step [8/8], Loss: 0.3775, Acc : 82.69231414794922%\n",
      "Epoch [93/100], Step [2/8], Loss: 0.3535, Acc : 84.375%\n",
      "Epoch [93/100], Step [4/8], Loss: 0.3044, Acc : 87.5%\n",
      "Epoch [93/100], Step [6/8], Loss: 0.3339, Acc : 84.1796875%\n",
      "Epoch [93/100], Step [8/8], Loss: 0.2920, Acc : 87.74038696289062%\n",
      "Epoch [94/100], Step [2/8], Loss: 0.3311, Acc : 85.546875%\n",
      "Epoch [94/100], Step [4/8], Loss: 0.3176, Acc : 85.9375%\n",
      "Epoch [94/100], Step [6/8], Loss: 0.3372, Acc : 85.7421875%\n",
      "Epoch [94/100], Step [8/8], Loss: 0.3354, Acc : 85.5769271850586%\n",
      "Epoch [95/100], Step [2/8], Loss: 0.3062, Acc : 87.3046875%\n",
      "Epoch [95/100], Step [4/8], Loss: 0.3902, Acc : 81.8359375%\n",
      "Epoch [95/100], Step [6/8], Loss: 0.3360, Acc : 82.8125%\n",
      "Epoch [95/100], Step [8/8], Loss: 0.3487, Acc : 85.33654022216797%\n",
      "Epoch [96/100], Step [2/8], Loss: 0.2721, Acc : 88.8671875%\n",
      "Epoch [96/100], Step [4/8], Loss: 0.3006, Acc : 86.5234375%\n",
      "Epoch [96/100], Step [6/8], Loss: 0.3337, Acc : 85.3515625%\n",
      "Epoch [96/100], Step [8/8], Loss: 0.3629, Acc : 83.65384674072266%\n",
      "Epoch [97/100], Step [2/8], Loss: 0.2964, Acc : 86.71875%\n",
      "Epoch [97/100], Step [4/8], Loss: 0.3250, Acc : 84.9609375%\n",
      "Epoch [97/100], Step [6/8], Loss: 0.3236, Acc : 85.9375%\n",
      "Epoch [97/100], Step [8/8], Loss: 0.3277, Acc : 86.29808044433594%\n",
      "Epoch [98/100], Step [2/8], Loss: 0.3169, Acc : 85.9375%\n",
      "Epoch [98/100], Step [4/8], Loss: 0.3079, Acc : 86.71875%\n",
      "Epoch [98/100], Step [6/8], Loss: 0.3028, Acc : 86.71875%\n",
      "Epoch [98/100], Step [8/8], Loss: 0.3135, Acc : 84.61538696289062%\n",
      "Epoch [99/100], Step [2/8], Loss: 0.3193, Acc : 86.328125%\n",
      "Epoch [99/100], Step [4/8], Loss: 0.3158, Acc : 85.546875%\n",
      "Epoch [99/100], Step [6/8], Loss: 0.3397, Acc : 83.59375%\n",
      "Epoch [99/100], Step [8/8], Loss: 0.3104, Acc : 86.05769348144531%\n",
      "Epoch [100/100], Step [2/8], Loss: 0.3332, Acc : 84.5703125%\n",
      "Epoch [100/100], Step [4/8], Loss: 0.3165, Acc : 86.9140625%\n",
      "Epoch [100/100], Step [6/8], Loss: 0.2759, Acc : 88.28125%\n",
      "Epoch [100/100], Step [8/8], Loss: 0.3225, Acc : 85.5769271850586%\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "data = dataiter.next()\n",
    "features,labels = data\n",
    "\n",
    "class StutterNet(nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super(StutterNet, self).__init__()\n",
    "        # input shape = (batch_size, 1, 149,768)\n",
    "        # in_channels is batch size\n",
    "        self.layer1 = nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels = 1, out_channels = 8, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=0.5)\n",
    "        )\n",
    "        # input size = (batch_size, 8, 74, 384)\n",
    "        self.layer2 = nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=1, stride=2),\n",
    "            torch.nn.Dropout(p=0.5)\n",
    "        )\n",
    "        # input size = (batch_size, 16, 37, 192)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc1 = nn.Linear(16* 37* 192,2, bias=True)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print('Before Layer1',np.shape(x))\n",
    "        out = self.layer1(x)\n",
    "        #print('After layer 1',np.shape(out))\n",
    "        out = self.layer2(out)\n",
    "        #print('After layer 2',np.shape(out))\n",
    "        out  = self.flatten(out)\n",
    "        out = self.fc1(out)\n",
    "        #print('After final ',np.shape(out))\n",
    "\n",
    "        log_probs = torch.nn.functional.log_softmax(out, dim=1)\n",
    "\n",
    "        return log_probs\n",
    "\n",
    "model = StutterNet(batch_size).to(device)\n",
    "print(model)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#weighted loss\n",
    "#criterion = nn.CrossEntropyLoss(weight = torch.FloatTensor([1, 3]).to(device)) # Class 0 is 75% of the total dataset \n",
    "#criterion = nn.LogSoftmax()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "loss_hist = []\n",
    "epoch_hist = []\n",
    "# Train the model\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    n_correct = 0\n",
    "    for i, (features, labels) in enumerate(train_loader):  \n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = torch.reshape(labels,(np.shape(labels)[0],))\n",
    "        labels = labels.to(torch.int64)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_hist.append(loss.cpu().detach().numpy())\n",
    "        epoch_hist.append(epoch*np.ceil(n_samples_train/batch_size)+i)\n",
    "\n",
    "        # Compute Training Accuracy\n",
    "        _, predicted_labels = torch.max(outputs.data, 1)\n",
    "        n_correct = (labels == predicted_labels).sum()\n",
    "        acc = 100.0 * n_correct / outputs.shape[0]\n",
    "        # visualisation\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)  \n",
    "        writer.add_scalar(\"Accuracy/train\", acc, epoch)  \n",
    "        \n",
    "        if (i+1) % 2 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}, Acc : {acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff14a427dc0>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_hist, loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff14a5c19d0>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_hist, loss_hist)\n",
    "# 0.1, 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff14a600ac0>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lr 1e-4\n",
    "plt.plot(epoch_hist, loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1])\n",
      "torch.Size([198, 1, 149, 768])\n",
      "torch.Size([198, 2])\n",
      "tensor([1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "        1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "        0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "torch.Size([198])\n",
      "0\n",
      "Accuracy of the network on test dataset is : 65.65656565656566 %\n",
      "Precision of the network on test dataset is : 0.6371681415929203\n",
      "Recall of the network on test dataset is : 0.7272727272727273\n",
      "F1 Score of the network on test dataset is : 0.679245283018868\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=1)\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "   n_correct = 0\n",
    "   # Compute F1 score, precision and recall\n",
    "   predicted_stutter = 0\n",
    "   labels_stutter = 0\n",
    "   correct_stutter = 0\n",
    "   i = 0\n",
    "   final_label = []\n",
    "   final_predicted = []\n",
    "   for features, labels in test_loader:\n",
    "       print(labels)\n",
    "       print(np.shape(features))\n",
    "       features = features.to(device)\n",
    "       labels = labels.to(device)\n",
    "       outputs = model(features)\n",
    "       print(np.shape(outputs))\n",
    "       # max returns (value ,index)\n",
    "       _, predicted = torch.max(outputs.data, 1)\n",
    "       print(predicted)\n",
    "       print(np.shape(predicted))\n",
    "       label = torch.transpose(predicted, -1, 0)\n",
    "       predicted = torch.reshape(predicted,(outputs.shape[0],1))\n",
    "       i = i+1\n",
    "       print(n_correct)\n",
    "       final_label.append(label)\n",
    "       final_predicted.append(predicted)\n",
    "       for i in range (0, outputs.shape[0]) :\n",
    "               # F1 score for stutter\n",
    "            if (predicted[i] == 1) :\n",
    "                predicted_stutter +=1\n",
    "            if (labels[i] == 1) :\n",
    "                labels_stutter +=1   \n",
    "            if ((predicted[i] == 1) & (labels[i] == 1)):\n",
    "                correct_stutter +=1\n",
    "            if (predicted[i] == labels[i]) :\n",
    "                n_correct = n_correct + 1\n",
    "\n",
    "\n",
    "\n",
    "acc_test = 100*n_correct/n_samples_test\n",
    "print(f'Accuracy of the network on test dataset is : {acc_test} %')\n",
    "recall = correct_stutter/ labels_stutter\n",
    "precision = correct_stutter / predicted_stutter\n",
    "f1_score = 2 * precision * recall / (precision + recall)    \n",
    "print(f'Precision of the network on test dataset is : {precision}')\n",
    "print(f'Recall of the network on test dataset is : {recall}')\n",
    "print(f'F1 Score of the network on test dataset is : {f1_score}')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0], device='cuda:0'), tensor([1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1], device='cuda:0'), tensor([0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1], device='cuda:0'), tensor([1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1], device='cuda:0'), tensor([1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0'), tensor([1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1], device='cuda:0'), tensor([1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0], device='cuda:0'), tensor([1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1], device='cuda:0'), tensor([1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0'), tensor([0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0], device='cuda:0'), tensor([1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1], device='cuda:0'), tensor([0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1], device='cuda:0'), tensor([1, 0, 1, 0, 1, 0], device='cuda:0')]\n",
      "-------------------------------------\n",
      "Predicted\n",
      "[tensor([[0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0]], device='cuda:0'), tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], device='cuda:0'), tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1]], device='cuda:0'), tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], device='cuda:0'), tensor([[1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1]], device='cuda:0'), tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], device='cuda:0'), tensor([[1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0'), tensor([[1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], device='cuda:0'), tensor([[1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]], device='cuda:0'), tensor([[0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0]], device='cuda:0'), tensor([[1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1]], device='cuda:0'), tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]], device='cuda:0'), tensor([[1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')]\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(final_label)\n",
    "print('-------------------------------------')\n",
    "print('Predicted')\n",
    "print(final_predicted)\n",
    "print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4aede6801b29297ca4753447bcd9fb52ef6084259d335c2409ba40d2da343a20"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
